{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Immigration Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project intends to prepare an analytical database for the study of immigration into the United States based on the I94 data. This incorporates the design of an ETL process which includes data modeling (i.e. a database schema) and data cleansing. The main focus of the analytical database will lie on:\n",
    "\n",
    "* Mode of entrance (vehicle and visa type)\n",
    "* Destination and origin of travel\n",
    "* Date of entrance and duration of stay in the country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The project consists of the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# We will be using PySpark, as will be justified later:\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, expr, pandas_udf, year, month, dayofmonth, col, lit\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "*Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We intend to make a database model, i.e. design a database relationship model, and an ETL process. \n",
    "Our main tools will be `Pandas` for initial data exploration, and -- for the heavy weight lifting -- Spark (in particular `PySpark`). For data storage, we will use `Parquet` since this data format allows for fast and efficient querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Describe and Gather Data \n",
    "*Describe the data sets you're using. Where did it come from? What type of information is included?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will use US immigration data from the year 2016 which has been provided by the US National Tourism and Trade office through its website. This dataset includes data such as the place of immigration (border), the visa type, the date of arrival, the duration of stay, and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## US immigration data from the year 2016 - Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721257</td>\n",
       "      <td>1481650.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>10072016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>7.368526e+08</td>\n",
       "      <td>910</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1072780</td>\n",
       "      <td>2197173.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>20556.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>10112016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CX</td>\n",
       "      <td>7.863122e+08</td>\n",
       "      <td>870</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112205</td>\n",
       "      <td>232708.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>06302016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>5.547449e+10</td>\n",
       "      <td>00117</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2577162</td>\n",
       "      <td>5227851.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>CHI</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>07262016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LX</td>\n",
       "      <td>5.941342e+10</td>\n",
       "      <td>00008</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10930</td>\n",
       "      <td>13213.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>5.544979e+10</td>\n",
       "      <td>00109</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "5      721257  1481650.0  2016.0     4.0   577.0   577.0     ATL  20552.0   \n",
       "6     1072780  2197173.0  2016.0     4.0   245.0   245.0     SFR  20556.0   \n",
       "7      112205   232708.0  2016.0     4.0   113.0   135.0     NYC  20546.0   \n",
       "8     2577162  5227851.0  2016.0     4.0   131.0   131.0     CHI  20572.0   \n",
       "9       10930    13213.0  2016.0     4.0   116.0   116.0     LOS  20545.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "5      1.0      GA    ...         NaN        M   1965.0  10072016       M   \n",
       "6      1.0      CA    ...         NaN        M   1968.0  10112016       F   \n",
       "7      1.0      NY    ...         NaN        M   1983.0  06302016       F   \n",
       "8      1.0      IL    ...         NaN        M   1977.0  07262016     NaN   \n",
       "9      1.0      CA    ...         NaN        M   1981.0  06292016     NaN   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "5    NaN      DL  7.368526e+08    910        B2  \n",
       "6    NaN      CX  7.863122e+08    870        B2  \n",
       "7    NaN      BA  5.547449e+10  00117        WT  \n",
       "8    NaN      LX  5.941342e+10  00008        WT  \n",
       "9    NaN      AA  5.544979e+10  00109        WT  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas = pd.read_csv('immigration_data_sample.csv')\n",
    "df_pandas.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Airport Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas = pd.read_csv('airport-codes_csv.csv')\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Demographics of US-Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strictly speaking, semicolon-separated data:\n",
    "df_pandas = pd.read_csv('us-cities-demographics.csv', sep=';')\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_pandas = pd.read_csv(fname)\n",
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Utilizing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since this is only a sample, we will try out Pandas with the monthly data of the whole dataset. As per the instructions, the raw immigration data is stored in the directory `../../data/18-83510-I94-Data-2016/` and is partitioned into monthly datasets as indicated by three-letter month codes, e.g. `i94_jan16_sub.sas7bdat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = '../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat'\n",
    "df_pandas = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As expected, the processing takes too long, and we will have to utilize a genuine big data toolbox: *Spark*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()\n",
    "\n",
    "df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_jan16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In order to work more efficiently with higher i/o-performance, we will convert the raw immigration data into **Parquet** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Work with parquet\n",
    "df.write.parquet(\"data_parquet/exploration\")\n",
    "df = spark.read.parquet(\"data_parquet/exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"data_parquet/exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For reference: Number of rows in the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847924"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|      admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "|  7.0|2016.0|   1.0| 101.0| 101.0|    BOS|20465.0|    1.0|     MA|   null|  20.0|    3.0|  1.0|    null|    null| null|      T|   null|   null|   null| 1996.0|     D/S|     M|  null|     LH|3.46608285E8|  424|      F1|\n",
      "|  8.0|2016.0|   1.0| 101.0| 101.0|    BOS|20465.0|    1.0|     MA|   null|  20.0|    3.0|  1.0|    null|    null| null|      T|   null|   null|   null| 1996.0|     D/S|     M|  null|     LH|3.46627585E8|  424|      F1|\n",
      "|  9.0|2016.0|   1.0| 101.0| 101.0|    BOS|20469.0|    1.0|     CT|20480.0|  17.0|    2.0|  1.0|    null|    null| null|      T|      N|   null|      M| 1999.0|07152016|     F|  null|     AF|3.81092385E8|  338|      B2|\n",
      "| 10.0|2016.0|   1.0| 101.0| 101.0|    BOS|20469.0|    1.0|     CT|20499.0|  45.0|    2.0|  1.0|    null|    null| null|      T|      N|   null|      M| 1971.0|07152016|     F|  null|     AF|3.81087885E8|  338|      B2|\n",
      "| 11.0|2016.0|   1.0| 101.0| 101.0|    BOS|20469.0|    1.0|     CT|20499.0|  12.0|    2.0|  1.0|    null|    null| null|      T|      N|   null|      M| 2004.0|07152016|     M|  null|     AF|3.81078685E8|  338|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "*Identify data quality issues, like missing values, duplicate data, etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "*Document steps necessary to clean the data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We are looking for the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"data_parquet/exploration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2847924"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of entries before cleaning:\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.filter(\"i94cit == i94res\")\\\n",
    "        .filter(\"i94addr != ''\")\\\n",
    "        .filter(\"i94mode is not null\")\\\n",
    "        .filter(\"arrdate is not null\")\\\n",
    "        .filter(\"depdate is not null\")\\\n",
    "        .filter(\"i94visa is not null\")\\\n",
    "        .filter(\"visatype != ''\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1786071"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1786071"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I.e., it seems like there weren't any duplicates left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('immigration_id', expr('cast(cicid as int)')).withColumn('origin_id', expr('cast(i94cit as int)')).withColumn('visa_id', expr('cast(i94visa as int)')).withColumn('mode_id', expr('cast(i94mode as int)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_timestamp_from_sas = udf(lambda sas: datetime.datetime(1960, 1, 1) + datetime.timedelta(days=int(sas)), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('arrival_date', get_timestamp_from_sas(df.arrdate)).withColumn('departure_date', get_timestamp_from_sas(df.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string, immigration_id: int, origin_id: int, visa_id: int, mode_id: int, arrival_date: timestamp, departure_date: timestamp]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.selectExpr('immigration_id', 'origin_id', 'i94addr as destination', \n",
    "                                                 'arrival_date', 'departure_date', 'dayofmonth(arrival_date) as day', 'month(arrival_date) as month', 'year(arrival_date) as year',\n",
    "                                                 'mode_id', 'visa_id', 'visatype as visa_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(immigration_id=9, origin_id=101, destination='CT', arrival_date=datetime.datetime(2016, 1, 16, 0, 0), departure_date=datetime.datetime(2016, 1, 27, 0, 0), day=16, month=1, year=2016, mode_id=1, visa_id=2, visa_type_id='B2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Better use show() when using PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|       arrival_date|     departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|             9|      101|         CT|2016-01-16 00:00:00|2016-01-27 00:00:00| 16|    1|2016|      1|      2|          B2|\n",
      "|            10|      101|         CT|2016-01-16 00:00:00|2016-02-15 00:00:00| 16|    1|2016|      1|      2|          B2|\n",
      "|            11|      101|         CT|2016-01-16 00:00:00|2016-02-15 00:00:00| 16|    1|2016|      1|      2|          B2|\n",
      "|            15|      101|         MA|2016-01-24 00:00:00|2016-03-11 00:00:00| 24|    1|2016|      1|      3|          F1|\n",
      "|            20|      101|         IL|2016-01-20 00:00:00|2016-01-29 00:00:00| 20|    1|2016|      1|      2|          B2|\n",
      "|            21|      101|         TN|2016-01-25 00:00:00|2016-02-11 00:00:00| 25|    1|2016|      1|      2|          B2|\n",
      "|            24|      101|         MI|2016-01-23 00:00:00|2016-02-24 00:00:00| 23|    1|2016|      1|      2|          B2|\n",
      "|            25|      101|         MI|2016-01-23 00:00:00|2016-02-24 00:00:00| 23|    1|2016|      1|      2|          B2|\n",
      "|            32|      101|         FL|2016-01-18 00:00:00|2016-02-17 00:00:00| 18|    1|2016|      1|      2|          B2|\n",
      "|            36|      101|         TN|2016-01-13 00:00:00|2016-01-26 00:00:00| 13|    1|2016|      1|      2|          B2|\n",
      "|            37|      101|         TN|2016-01-13 00:00:00|2016-01-26 00:00:00| 13|    1|2016|      1|      2|          B2|\n",
      "|            40|      101|         NY|2016-01-21 00:00:00|2016-01-28 00:00:00| 21|    1|2016|      1|      2|          B2|\n",
      "|            41|      101|         NY|2016-01-21 00:00:00|2016-02-07 00:00:00| 21|    1|2016|      1|      2|          B2|\n",
      "|            42|      101|         NY|2016-01-21 00:00:00|2016-02-21 00:00:00| 21|    1|2016|      1|      2|          B2|\n",
      "|            46|      101|         NY|2016-01-29 00:00:00|2016-02-07 00:00:00| 29|    1|2016|      1|      1|          B1|\n",
      "|            47|      101|         NY|2016-01-29 00:00:00|2016-02-07 00:00:00| 29|    1|2016|      1|      1|          B1|\n",
      "|            58|      101|         NY|2016-01-13 00:00:00|2016-03-28 00:00:00| 13|    1|2016|      1|      2|          B2|\n",
      "|            60|      101|         NJ|2016-01-15 00:00:00|2016-03-09 00:00:00| 15|    1|2016|      1|      3|          F1|\n",
      "|            62|      101|         NY|2016-01-16 00:00:00|2016-03-30 00:00:00| 16|    1|2016|      1|      2|          B2|\n",
      "|            63|      101|         NY|2016-01-19 00:00:00|2016-02-01 00:00:00| 19|    1|2016|      1|      2|          B2|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "*Map out the conceptual data model and explain why you chose that model*\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "*List the steps necessary to pipeline the data into the chosen data model*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We select a star schema with a fact table in the middle, and four supplemental dimensional tables. The fact table will provide us with sufficiently fast OLAP performance while the much smaller dimensional tables contain additional information.\n",
    "\n",
    "The ETL-pipeline will not be too complicated, as the immigration dataset already contains all the information required for the fact table. As a result, no JOIN-operations are required, and the pipeline mostly consists of ignoring certain columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<img src='images/ER_diagram.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "## 4.1 Create the data model\n",
    "*Build the data pipelines to create the data model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.1.1 Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As already mentioned, the ETL pipeline for the fact table is rather simple to realize, i.e. JOINS are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    Description: Load the data\n",
    "    Arguments:   file: Filename of sas7bdat-file\n",
    "    Returns:     None\n",
    "    \"\"\"\n",
    "    file = '../../data/18-83510-I94-Data-2016/{}'.format(file)\n",
    "    df = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Description: Clean the data\n",
    "    Arguments:   df: (Spark-)dataframe\n",
    "    Returns:     Processed (Spark-)dataframe\n",
    "    \"\"\"\n",
    "    df = df.filter(\"i94cit == i94res\")\\\n",
    "        .filter(\"i94addr != ''\")\\\n",
    "        .filter(\"i94mode is not null\")\\\n",
    "        .filter(\"arrdate is not null\")\\\n",
    "        .filter(\"depdate is not null\")\\\n",
    "        .filter(\"i94visa is not null\")\\\n",
    "        .filter(\"visatype != ''\")\n",
    "    return df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ids_columns(df):\n",
    "    \"\"\"\n",
    "    Description: ds\n",
    "    Arguments: (Spark-)dataframe\n",
    "    Returns:   Processed (Spark-)dataframe\n",
    "    \"\"\"\n",
    "    return df.withColumn('immigration_id', expr('cast(cicid as int)')).withColumn('origin_id', expr('cast(i94cit as int)')).withColumn('visa_id', expr('cast(i94visa as int)')).withColumn('mode_id', expr('cast(i94mode as int)'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_timestamp_from_sas = udf(lambda sas: datetime.datetime(1960, 1, 1) + datetime.timedelta(days=int(sas)), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_column_dates_from_sas_to_timestamp(df):\n",
    "    \"\"\"\n",
    "    Description: asd\n",
    "    Arguments:   df: (Spark-)dataframe\n",
    "    Returns:     df: Processed (Spark-)dataframe\n",
    "    \"\"\"\n",
    "    return df.withColumn('arrival_date', get_timestamp_from_sas(df.arrdate)).withColumn('departure_date', get_timestamp_from_sas(df.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def select_columns(df):\n",
    "    \"\"\"\n",
    "    Description: asd\n",
    "    Arguments:   df: (Spark-)dataframe\n",
    "    Returns:     df: Processed (Spark-)dataframe\n",
    "    \"\"\"\n",
    "    return df.selectExpr('immigration_id', 'origin_id', 'i94addr as destination', 'arrival_date', 'month(arrival_date) as arrival_month', 'departure_date', 'mode_id', 'visa_id', 'visatype as visa_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def etl_pipeline(batch):\n",
    "    \"\"\"\n",
    "    Description: The ETL-Pipeline. Processes a batch of sas-files.\n",
    "    Arguments:   batch: List of parquet-filenames\n",
    "    Returns:     None\n",
    "    \"\"\"\n",
    "    for num, name in enumerate(batch, start=1):\n",
    "        df = load_data(name)\n",
    "        df = clean_data(df)\n",
    "        df = get_ids_columns(df)\n",
    "        df = get_column_dates_from_sas_to_timestamp(df)\n",
    "        df = select_columns(df)\n",
    "\n",
    "        #df.write.partitionBy('visa_type_id').parquet('data_parquet/{}/'.format(num), mode='overwrite')\n",
    "        df.write.partitionBy('arrival_month','visa_type_id').parquet('data_parquet/'.format(num), mode='append')\n",
    "\n",
    "        print(\"Processed file {}: {}\".format(num, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# A small batch for debugging purposes\n",
    "batch = [\n",
    "    'i94_jan16_sub.sas7bdat',\n",
    "    'i94_feb16_sub.sas7bdat',\n",
    "    'i94_mar16_sub.sas7bdat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We compile the file batch manually, as there are only twelve months to consider:\n",
    "batch = [\n",
    "    'i94_jan16_sub.sas7bdat',\n",
    "    'i94_feb16_sub.sas7bdat',\n",
    "    'i94_mar16_sub.sas7bdat',\n",
    "    'i94_apr16_sub.sas7bdat',\n",
    "    'i94_may16_sub.sas7bdat',\n",
    "    'i94_jun16_sub.sas7bdat',\n",
    "    'i94_jul16_sub.sas7bdat',\n",
    "    'i94_aug16_sub.sas7bdat',\n",
    "    'i94_sep16_sub.sas7bdat',\n",
    "    'i94_oct16_sub.sas7bdat',\n",
    "    'i94_nov16_sub.sas7bdat',\n",
    "    'i94_dec16_sub.sas7bdat'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Having prepared the pipeline above, we are set and ready to trigger the ETL-pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file 1: i94_jan16_sub.sas7bdat\n",
      "Processed file 2: i94_feb16_sub.sas7bdat\n",
      "Processed file 3: i94_mar16_sub.sas7bdat\n",
      "Processed file 4: i94_apr16_sub.sas7bdat\n",
      "Processed file 5: i94_may16_sub.sas7bdat\n",
      "Processed file 6: i94_jun16_sub.sas7bdat\n",
      "Processed file 7: i94_jul16_sub.sas7bdat\n",
      "Processed file 8: i94_aug16_sub.sas7bdat\n",
      "Processed file 9: i94_sep16_sub.sas7bdat\n",
      "Processed file 10: i94_oct16_sub.sas7bdat\n",
      "Processed file 11: i94_nov16_sub.sas7bdat\n",
      "Processed file 12: i94_dec16_sub.sas7bdat\n"
     ]
    }
   ],
   "source": [
    "etl_pipeline(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.1.2 Dim Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_country_of_origin = df.selectExpr('immigration_id', 'origin_id', 'i94addr as destination', \n",
    "                                                 'arrival_date', 'departure_date', 'dayofmonth(arrival_date) as day', 'month(arrival_date) as month', 'year(arrival_date) as year',\n",
    "                                                 'mode_id', 'visa_id', 'visatype as visa_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df_fullyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|origin_id|description|\n",
      "+---------+-----------+\n",
      "|      392|           |\n",
      "|      243|           |\n",
      "|      516|           |\n",
      "|      251|           |\n",
      "|      255|           |\n",
      "|      296|           |\n",
      "|      472|           |\n",
      "|      513|           |\n",
      "|      322|           |\n",
      "|      321|           |\n",
      "|      375|           |\n",
      "|      108|           |\n",
      "|      155|           |\n",
      "|      368|           |\n",
      "|      126|           |\n",
      "|      115|           |\n",
      "|      101|           |\n",
      "|      385|           |\n",
      "|      412|           |\n",
      "|      688|           |\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# country_of_origin\n",
    "\"\"\"\n",
    "    origin_id\n",
    "    description\n",
    "\"\"\"\n",
    "df_country_of_origin = df.selectExpr('origin_id').dropDuplicates()\\\n",
    "                        .withColumn('description', lit(''))\n",
    "df_country_of_origin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|visa_id|description|\n",
      "+-------+-----------+\n",
      "|      1|           |\n",
      "|      3|           |\n",
      "|      2|           |\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visa\n",
    "\"\"\"\n",
    "    visa_id\n",
    "    description\n",
    "\"\"\"\n",
    "df_visa = df.selectExpr('visa_id').dropDuplicates()\\\n",
    "                .withColumn('description', lit(''))\n",
    "df_visa.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-----+--------+\n",
      "|visa_type_id|description|class|subclass|\n",
      "+------------+-----------+-----+--------+\n",
      "|          F2|           |     |        |\n",
      "|         GMB|           |     |        |\n",
      "|          B2|           |     |        |\n",
      "|          F1|           |     |        |\n",
      "|         CPL|           |     |        |\n",
      "|          I1|           |     |        |\n",
      "|          WB|           |     |        |\n",
      "|          M1|           |     |        |\n",
      "|          B1|           |     |        |\n",
      "|          WT|           |     |        |\n",
      "|          M2|           |     |        |\n",
      "|          CP|           |     |        |\n",
      "|         GMT|           |     |        |\n",
      "|          E1|           |     |        |\n",
      "|           I|           |     |        |\n",
      "|          E2|           |     |        |\n",
      "|         SBP|           |     |        |\n",
      "+------------+-----------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visa_types\n",
    "\"\"\"\n",
    "    visa_type_id\n",
    "    description\n",
    "    class\n",
    "    subclass\n",
    "\"\"\"\n",
    "df_visa_types = df.selectExpr('visa_type_id').dropDuplicates()\\\n",
    "                    .withColumn('description', lit(''))\\\n",
    "                    .withColumn('class', lit(''))\\\n",
    "                    .withColumn('subclass', lit(''))\n",
    "df_visa_types.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|mode_id|type|\n",
      "+-------+----+\n",
      "|      1|    |\n",
      "|      3|    |\n",
      "|      9|    |\n",
      "|      2|    |\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# immigration_modes\n",
    "\"\"\"\n",
    "    mode_id\n",
    "    type\n",
    "\"\"\"\n",
    "df_immigration_modes = df.selectExpr('mode_id').dropDuplicates()\\\n",
    "                            .withColumn('type', lit(''))\n",
    "df_immigration_modes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "*Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:*\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "*Run Quality Checks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Test if the dataframe has the expected amount of columns and these are of the expected dtypes: `data_quality_dtypes()`\n",
    "* Test if the dataframes are not empty: `data_quality_emptiness()`\n",
    "* Test if the given keys are a unique set in the dataframe: `data_quality_key()`\n",
    "* Test if there are trivial ('') or NULL entries in certain columns: `data_quality_nontrivial()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Start Spark-session in case of a cold start (import module dependencies on the top of the nb):\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We start with developing a testing strategy for the month of January, and just take a short glance at the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+-------------------+-------------------+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|       arrival_date|     departure_date|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+-------------------+-------------------+-------+-------+------------+\n",
      "|          1153|      107|         IL|2016-01-16 00:00:00|2016-01-30 00:00:00|      1|      2|          B2|\n",
      "|         16124|      131|         NY|2016-01-08 00:00:00|2016-01-12 00:00:00|      1|      2|          B2|\n",
      "|         26940|      165|         CA|2016-01-01 00:00:00|2016-03-21 00:00:00|      1|      2|          B2|\n",
      "|         28627|      209|         GU|2016-01-06 00:00:00|2016-01-09 00:00:00|      1|      2|          B2|\n",
      "|         46913|      245|         IL|2016-01-08 00:00:00|2016-01-31 00:00:00|      1|      2|          B2|\n",
      "|         47174|      245|         OH|2016-01-14 00:00:00|2016-04-14 00:00:00|      1|      2|          B2|\n",
      "|         47442|      245|         WI|2016-01-21 00:00:00|2016-03-18 00:00:00|      1|      2|          B2|\n",
      "|         47629|      245|         CA|2016-01-29 00:00:00|2016-02-15 00:00:00|      1|      2|          B2|\n",
      "|         47714|      245|         TX|2016-01-22 00:00:00|2016-02-07 00:00:00|      1|      2|          B2|\n",
      "|         52709|      245|         CA|2016-01-23 00:00:00|2016-02-12 00:00:00|      1|      2|          B2|\n",
      "|         62044|      245|         CA|2016-01-17 00:00:00|2016-01-22 00:00:00|      1|      2|          B2|\n",
      "|         62872|      250|         CA|2016-01-17 00:00:00|2016-01-26 00:00:00|      1|      2|          B2|\n",
      "|         63171|      251|         NV|2016-01-20 00:00:00|2016-02-09 00:00:00|      1|      2|          B2|\n",
      "|         63904|      253|         II|2016-01-23 00:00:00|2016-03-27 00:00:00|      1|      2|          B2|\n",
      "|         70114|      258|         IL|2016-01-14 00:00:00|2016-02-09 00:00:00|      1|      2|          B2|\n",
      "|         70706|      258|         TX|2016-01-21 00:00:00|2016-02-15 00:00:00|      1|      2|          B2|\n",
      "|         71609|      258|         NJ|2016-01-06 00:00:00|2016-01-07 00:00:00|      1|      2|          B2|\n",
      "|         78175|      261|         FL|2016-01-11 00:00:00|2016-01-21 00:00:00|      1|      2|          B2|\n",
      "|         78447|      261|         MD|2016-01-04 00:00:00|2016-01-18 00:00:00|      1|      2|          B2|\n",
      "|         82564|      263|         NV|2016-01-18 00:00:00|2016-01-23 00:00:00|      1|      2|          B2|\n",
      "+--------------+---------+-----------+-------------------+-------------------+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1786071"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_january = spark.read.parquet('data_parquet/arrival_month=1/')\n",
    "df_january.show()\n",
    "df_january.count()\n",
    "#january_df.toPandas().shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Test that the dataframe is non-empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_emptiness(df):\n",
    "    if df.select(\"*\").filter(\"immigration_id IS NULL OR immigration_id = ''\").count() == 0:\n",
    "        print(\"Data frame is non-empty: Passed!\")\n",
    "    else:\n",
    "        raise ValueError(\"Data frame is empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame is non-empty: Passed!\n"
     ]
    }
   ],
   "source": [
    "data_quality_emptiness(df_january)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Test the expected number of columns and their respective data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('immigration_id', 'int'),\n",
       " ('origin_id', 'int'),\n",
       " ('destination', 'string'),\n",
       " ('arrival_date', 'timestamp'),\n",
       " ('departure_date', 'timestamp'),\n",
       " ('mode_id', 'int'),\n",
       " ('visa_id', 'int'),\n",
       " ('visa_type_id', 'string')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_january.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "expected_data_types = [\n",
    "    ('immigration_id', 'int'),\n",
    "    ('origin_id', 'int'),\n",
    "    ('destination', 'string'),\n",
    "    ('arrival_date', 'timestamp'),\n",
    "    ('departure_date', 'timestamp'),\n",
    "    ('mode_id', 'int'),\n",
    "    ('visa_id', 'int'),\n",
    "    ('visa_type_id', 'string'),\n",
    "    ('arrival_month', 'int')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_dtypes(df, expected_data_types):\n",
    "    if df.dtypes == expected_data_types:\n",
    "        print(\"Data frame has the expected data types: Passed!\")\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected data type!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame has the expected data types: Passed!\n"
     ]
    }
   ],
   "source": [
    "data_quality_dtypes(df_january, expected_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Check that all entries in certain columns are non-trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "null_checks = [\n",
    "    \"immigration_id IS NULL OR immigration_id = ''\",\n",
    "    \"origin_id IS NULL\",\n",
    "    \"mode_id IS NULL\",\n",
    "    \"visa_id IS NULL\",\n",
    "    \"visa_type_id IS NULL OR visa_type_id = ''\"    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_nontrivial(df, filter_list):\n",
    "    \"\"\"\n",
    "    Description: Runs the quality checks defined as a list of SQL expressions on a (Spark-)dataframe.\n",
    "    Arguments:   df:    (Spark-)dataframe to be tested\n",
    "                 tests: List of tests defined as SQL-expressions\n",
    "    Returns:     None\n",
    "    \"\"\"\n",
    "    for num, filter_statement in enumerate(filter_list):\n",
    "        print(f\"Test {num+1}/{len(filter_list)}:\\t\", end = \"\")\n",
    "        if df.select(\"*\").filter(filter_statement).count() == 0:\n",
    "            print(\"Quality check o.k.\")\n",
    "        else:\n",
    "            raise ValueError(\"Quality check failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/5:\tQuality check o.k.\n",
      "Test 2/5:\tQuality check o.k.\n",
      "Test 3/5:\tQuality check o.k.\n",
      "Test 4/5:\tQuality check o.k.\n",
      "Test 5/5:\tQuality check o.k.\n"
     ]
    }
   ],
   "source": [
    "data_quality_nontrivial(df=january_df, filter_list=null_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here, we check that the pair (`immigration_id`, `arrival_month`) is unique over the whole year. Since `immigration_id` alone starts at zero or one again at the start of each month, it leads to collisions when merging the data of mulitple months, and hence cannot serve as a primary key in a SQL-database (such as AWS Redshift).\n",
    "Therefore, we either introduce a new SERIAL when loading into a relational DB, or consider (`immigration_id`, `arrival_month`) a key for the table `immigrations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_quality_key(df):\n",
    "    #primary_key = df.columns[0]\n",
    "    #query = \"SELECT {0}, COUNT(*) FROM immigrations GROUP BY {0} HAVING COUNT(*) > 1\".format(primary_key)\n",
    "    query = \"SELECT immigration_id, arrival_month, COUNT(*) FROM immigrations GROUP BY immigration_id, arrival_month HAVING COUNT(*) > 1\"\n",
    "    df.createOrReplaceTempView(\"immigrations\")\n",
    "    count = spark.sql(query).count()\n",
    "    if count == 0:\n",
    "        print(\"Quality check passed\")\n",
    "    else:\n",
    "        raise ValueError(\"Quality check failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed\n"
     ]
    }
   ],
   "source": [
    "data_quality_key(df_january)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The Checks for January look okay, so we pursue with the whole year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_fullyear = spark.read.parquet('data_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[immigration_id: int, origin_id: int, destination: string, arrival_date: timestamp, departure_date: timestamp, mode_id: int, visa_id: int, visa_type_id: string, arrival_month: int]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fullyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame is non-empty: Passed!\n"
     ]
    }
   ],
   "source": [
    "data_quality_emptiness(df_fullyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check passed\n"
     ]
    }
   ],
   "source": [
    "data_quality_key(df_fullyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame has the expected data types: Passed!\n"
     ]
    }
   ],
   "source": [
    "data_quality_dtypes(df_fullyear, expected_data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/5:\tQuality check o.k.\n",
      "Test 2/5:\tQuality check o.k.\n",
      "Test 3/5:\tQuality check o.k.\n",
      "Test 4/5:\tQuality check o.k.\n",
      "Test 5/5:\tQuality check o.k.\n"
     ]
    }
   ],
   "source": [
    "data_quality_nontrivial(df=df_fullyear, filter_list=null_checks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "*Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data dictionary of the database is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Table: `immigrations`\n",
    "\n",
    "| Attribute | Description |\n",
    "|-------|-------|\n",
    "|immigration_id | unique identifier of immigration |\n",
    "|origin_id | this value represents the location where the person came and is the same value as i94cit and i94res columns  |\n",
    "|destination | state where the immigrant arrive (i94addr column) |\n",
    "|arrival_date| data that the person arrived in the us (datetime based in column arrdate) |\n",
    "|departure_time| data that the person left in the us (datetime based in column dapdate) |\n",
    "|mode_id| vehicle used to enter the country and this value is from i94mode |\n",
    "|visa_id| type of immigrant is the same value as i94visa column |\n",
    "|visa_type_id| visa type is the same value as visatype column |\n",
    "\n",
    "\n",
    "#### Dim Table: `country_of_origin`\n",
    "\n",
    "| Attribute | Description |\n",
    "|-------|-------|\n",
    "|origin_id| valid and invalid codes which indicates the location where the person came from |\n",
    "|description| location name |\n",
    "\n",
    "\n",
    "#### Dim Table: `visa`\n",
    "\n",
    "| Attribute | Description |\n",
    "|-------|-------|\n",
    "|visa_id| value which indicate the type of immigrant |\n",
    "|sescription| type name |\n",
    "\n",
    "#### Dim Table: `immigration_modes`\n",
    "\n",
    "| Attribute | Description |\n",
    "|-------|-------|\n",
    "|mode_id| value which represent the vehicle used to enter the country |\n",
    "|type| type of vehicle |\n",
    "\n",
    "#### Dim Table: `visa_types`\n",
    "\n",
    "| Attribute | Description |\n",
    "|-------|-------|\n",
    "|visa_type_id| code which indicate the visa type |\n",
    "|description| description about who hava access to this visa |\n",
    "|class| visa subclass |\n",
    "|subclass| visa class |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Example Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As an example, we query the number of immigrations between Jan. 10 and Jan. 20 2016:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|30093719|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('immigrations')\n",
    "spark.sql(\"SELECT COUNT(*) FROM immigrations\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|11131335|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM immigrations WHERE arrival_date > '2016-05-01' AND arrival_date < '2016-08-31'\"\n",
    "df.createOrReplaceTempView('immigrations')\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Bonus:** A histogram of the total immigration throughout the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fac8af7e588>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac8b0a3ac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "month_count = df.groupBy('arrival_month').count().select('arrival_month', 'count').toPandas()\n",
    "#month_count = month_count.set_index('arrival_month')\n",
    "month_count = month_count.sort_values(by=['arrival_month'])\n",
    "month_count.plot.bar(x='arrival_month', y='count', color='darkblue', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Although we have used Parquet for the analytical data in the project, the main target should be a scalable warehouse solution like `AWS Redshift`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In a realistic scenario, the provided data will be updated on a regular basis in a data lake. In order to make the most recent data available for fast analytical querying (e.g. for administrative or policy needs), the ETL process needs to update the database on a regular basis, for example on a monthly, weekly, or daily basis. One tool to realise this is `Apache Airflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "As for the update intervals, we propose a nightly update. `Airflow` (or alternatively `AWS Step Functions`) can be configured such that the import data would be available early in the morning. Assuming that daily data will be available in the data lake around midnight, the ETL process can be automatically started in the middle of the night."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "It has to be determined how long an incremental update takes on the given system (e.g. 2 or 3 hours), such that the start of this batch job can be set and the data can be available before office hours in the morning. In order to increase the data import throughput, an idea is to chunk the data to parallelize the input (and the number of nodes increased accordingly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Access to a higher userbase (e.g. more than 100 analysts) would require to scale the database appropriately to handle all incoming OLAP-requests (all read-only operations). At some point, it may be advantageous to mirror the data into a read-optimized database such as `Apache Cassandra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
